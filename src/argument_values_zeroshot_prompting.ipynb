{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Imports and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRYQLcIkXOFH",
    "outputId": "c5879ab2-6907-4c37-b092-dcbe4e8034fe"
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain-core openai tiktoken pandas scikit-learn torch typing_extensions libclang tensorflow-io-gcs-filesystem tensorflow\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from Prompting import Prompting\n",
    "from Processing import Processing\n",
    "from Evaluation import Evaluation\n",
    "from Plotting import Plotting\n",
    "from IO import IO\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IE3ENXSpOsua",
    "outputId": "adf40b6c-dc73-4951-dfd6-279e440043ac"
   },
   "outputs": [],
   "source": [
    "arguments = pd.read_csv('../data/arguments.tsv', sep='\\t', header=0)\n",
    "values = Processing.parse_value_file('../data/values.json')\n",
    "value_name_list = Processing.get_value_name_list(values)\n",
    "labels_level1 = pd.read_csv('../data/labels-level1.tsv', sep='\\t', header=0)\n",
    "labels_level2 = pd.read_csv('../data/labels-level2.tsv', sep='\\t', header=0)\n",
    "labels_level3 = pd.read_csv('../data/labels-level3.tsv', sep='\\t', header=0)\n",
    "labels_level4a = pd.read_csv('../data/labels-level4a.tsv', sep='\\t', header=0)\n",
    "labels_level4b = pd.read_csv('../data/labels-level4b.tsv', sep='\\t', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_arguments = arguments.loc[arguments[\"Usage\"] == \"test\"]\n",
    "labels_level1 = labels_level1[labels_level1[\"Argument ID\"].isin(test_arguments[\"Argument ID\"])]\n",
    "labels_level2 = labels_level2[labels_level2[\"Argument ID\"].isin(test_arguments[\"Argument ID\"])]\n",
    "labels_level3 = labels_level3[labels_level3[\"Argument ID\"].isin(test_arguments[\"Argument ID\"])]\n",
    "labels_level4a = labels_level4a[labels_level4a[\"Argument ID\"].isin(test_arguments[\"Argument ID\"])]\n",
    "labels_level4b = labels_level4b[labels_level4b[\"Argument ID\"].isin(test_arguments[\"Argument ID\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels_level4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usa_test_arguments = test_arguments.loc[arguments[\"Part\"] == \"usa\"]\n",
    "usa_labels_level1 = labels_level1[labels_level1[\"Argument ID\"].isin(usa_test_arguments[\"Argument ID\"])]\n",
    "usa_labels_level2 = labels_level2[labels_level2[\"Argument ID\"].isin(usa_test_arguments[\"Argument ID\"])]\n",
    "usa_labels_level3 = labels_level3[labels_level3[\"Argument ID\"].isin(usa_test_arguments[\"Argument ID\"])]\n",
    "usa_labels_level4a = labels_level4a[labels_level4a[\"Argument ID\"].isin(usa_test_arguments[\"Argument ID\"])]\n",
    "usa_labels_level4b = labels_level4b[labels_level4b[\"Argument ID\"].isin(usa_test_arguments[\"Argument ID\"])]\n",
    "\n",
    "africa_test_arguments = test_arguments.loc[arguments[\"Part\"] == \"africa\"]\n",
    "africa_labels_level1 = labels_level1[labels_level1[\"Argument ID\"].isin(africa_test_arguments[\"Argument ID\"])]\n",
    "africa_labels_level2 = labels_level2[labels_level2[\"Argument ID\"].isin(africa_test_arguments[\"Argument ID\"])]\n",
    "africa_labels_level3 = labels_level3[labels_level3[\"Argument ID\"].isin(africa_test_arguments[\"Argument ID\"])]\n",
    "africa_labels_level4a = labels_level4a[labels_level4a[\"Argument ID\"].isin(africa_test_arguments[\"Argument ID\"])]\n",
    "africa_labels_level4b = labels_level4b[labels_level4b[\"Argument ID\"].isin(africa_test_arguments[\"Argument ID\"])]\n",
    "\n",
    "china_test_arguments = test_arguments.loc[arguments[\"Part\"] == \"china\"]\n",
    "china_labels_level1 = labels_level1[labels_level1[\"Argument ID\"].isin(china_test_arguments[\"Argument ID\"])]\n",
    "china_labels_level2 = labels_level2[labels_level2[\"Argument ID\"].isin(china_test_arguments[\"Argument ID\"])]\n",
    "china_labels_level3 = labels_level3[labels_level3[\"Argument ID\"].isin(china_test_arguments[\"Argument ID\"])]\n",
    "china_labels_level4a = labels_level4a[labels_level4a[\"Argument ID\"].isin(china_test_arguments[\"Argument ID\"])]\n",
    "china_labels_level4b = labels_level4b[labels_level4b[\"Argument ID\"].isin(china_test_arguments[\"Argument ID\"])]\n",
    "\n",
    "india_test_arguments = test_arguments.loc[arguments[\"Part\"] == \"india\"]\n",
    "india_labels_level1 = labels_level1[labels_level1[\"Argument ID\"].isin(india_test_arguments[\"Argument ID\"])]\n",
    "india_labels_level2 = labels_level2[labels_level2[\"Argument ID\"].isin(india_test_arguments[\"Argument ID\"])]\n",
    "india_labels_level3 = labels_level3[labels_level3[\"Argument ID\"].isin(india_test_arguments[\"Argument ID\"])]\n",
    "india_labels_level4a = labels_level4a[labels_level4a[\"Argument ID\"].isin(india_test_arguments[\"Argument ID\"])]\n",
    "india_labels_level4b = labels_level4b[labels_level4b[\"Argument ID\"].isin(india_test_arguments[\"Argument ID\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "def zero_shot(policy, opinion, stance, llm, values):\n",
    "    template = (\n",
    "        \"Someone is {stance} the idea {policy}, arguing that {opinion}\"\n",
    "        \"We present a three-level categorization of values, your task is to select the appropriate level 1, 2, 3, 4a and 4b values represented by the argument\"\n",
    "        \"You need not consider arguments other than the presented one\"\n",
    "        \"The list of human values to choose from:\\n\"\n",
    "        \"{values_string}\"\n",
    "        \"Represent your answer as below:\"\n",
    "        \"### ANSWER FORMAT GUIDE ###\\n\"\n",
    "        \"Level 1 Values: <semicolon separated list of level 1 values>\"\n",
    "        \"Level 2 Values: <semicolon separated list of level 2 values>\"\n",
    "        \"Level 3 Values: <semicolon separated list of level 3 values>\"\n",
    "        \"Level 4A Values: <semicolon separated list of level 4A values>\"\n",
    "        \"Level 4B Values: <semicolon separated list of level 4B values>\"\n",
    "    )\n",
    "\n",
    "    values_string = Processing.stringify_values_for_prompt(values)\n",
    "\n",
    "    prompt = PromptTemplate(template=template, input_variables=['premise', 'conclusion', 'stance', 'values_string'])\n",
    "\n",
    "    runnable = prompt | llm | StrOutputParser()\n",
    "\n",
    "    answer = runnable.invoke({\n",
    "        \"opinion\": opinion,\n",
    "        \"policy\": policy,\n",
    "        \"stance\": stance,\n",
    "        \"values_string\": values_string\n",
    "    })\n",
    "\n",
    "    print(\"Total token count for input + output = \", Processing.num_tokens_from_string(template + values_string + str(answer), \"cl100k_base\"))\n",
    "\n",
    "    return answer\n",
    "\n",
    "policy = \"We should oppose collectivism\"\n",
    "opinion = \"treating everyone as a large group unit is not helpful for people who have different individual needs.\"\n",
    "stance = \"in favor of\"\n",
    "llm = ChatOpenAI(model_name = \"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "llm_answer = zero_shot(policy, opinion, stance, llm, values)\n",
    "print(llm_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(Processing.extract_values_real(llm_answer, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the data for the first DataFrame\n",
    "data1 = {'a': [1, 0, 1, 0],\n",
    "         'b': [0, 1, 0, 1],\n",
    "         'c': [1, 1, 0, 0],\n",
    "         'd': [0, 0, 1, 1],\n",
    "         'e': [1, 0, 1, 0]}\n",
    "# Create the first DataFrame\n",
    "df1 = pd.DataFrame(data1)\n",
    "\n",
    "# Define the data for the second DataFrame\n",
    "data2 = {'a': [0, 1, 1, 0],\n",
    "         'b': [1, 0, 1, 0],\n",
    "         'c': [0, 1, 1, 0],\n",
    "         'd': [1, 0, 0, 1],\n",
    "         'e': [0, 1, 0, 1]}\n",
    "# Create the second DataFrame\n",
    "df2 = pd.DataFrame(data2)\n",
    "\n",
    "# Display the DataFrames\n",
    "print(\"DataFrame 1:\")\n",
    "print(df1)\n",
    "print(\"\\nDataFrame 2:\")\n",
    "print(df2)\n",
    "\n",
    "print(Evaluation.f1_overview(df1, df2, ['a', 'b', 'c', 'd', 'e']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prompting models for accuracy estimate\n",
    "## GPT-3.5-Instruct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Plain zero-shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name = \"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "predicted_labels_zero_shot, true_labels_zero_shot = Prompting.zero_shot_sequence(test_arguments, values, llm, labels_level1, labels_level2, labels_level3, labels_level4a, labels_level4b, True, False)\n",
    "\n",
    "predicted_labels_zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_labels_zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def evaluate(predicted_labels, true_labels, values, zero_div):\n",
    "    levels = [\"Level 1\", \"Level 2\", \"Level 3\", \"Level 4A\", \"Level 4B\"]\n",
    "    overview = {}\n",
    "\n",
    "    for level in levels:\n",
    "        value_list = [value for value in values[level]]\n",
    "        l_pred = predicted_labels[value_list].copy()\n",
    "        l_true = true_labels[value_list].copy()\n",
    "        overview[level] = {\n",
    "            \"Micro-averaged\": precision_recall_fscore_support(l_true, l_pred, average=\"micro\", zero_division=zero_div),\n",
    "            \"Macro-averaged\": precision_recall_fscore_support(l_true, l_pred, average=\"macro\", zero_division=zero_div),\n",
    "            \"Weighted averaged\": precision_recall_fscore_support(l_true, l_pred, average=\"weighted\", zero_division=zero_div),\n",
    "            \"Per-value\": dict(\n",
    "                zip(value_list, precision_recall_fscore_support(l_true, l_pred, average=None, zero_division=zero_div)[2]))}\n",
    "\n",
    "    return overview\n",
    "\n",
    "# overview = evaluate(predicted_labels_zero_shot, true_labels_zero_shot, Processing.get_value_name_list(values))\n",
    "# overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_labels_zero_shot.to_csv('out.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Testing for USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name = \"gpt-3.5-turbo-0125\", temperature=0)\n",
    "\n",
    "usa_predicted_labels_zero_shot, usa_true_labels_zero_shot = Prompting.zero_shot_sequence(usa_test_arguments, values, llm, usa_labels_level1, usa_labels_level2, usa_labels_level3, usa_labels_level4a, usa_labels_level4b, True, False)\n",
    "\n",
    "usa_predicted_labels_zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usa_true_labels_zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usa_overview = evaluate(usa_predicted_labels_zero_shot, usa_true_labels_zero_shot, Processing.get_value_name_list(values), 1.0)\n",
    "usa_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_f1_per_value(overview_dict, level):\n",
    "    x = list(overview_dict[level][\"Per-value\"].keys())\n",
    "    y = list(overview_dict[level][\"Per-value\"].values())\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.plot(x, y, marker='.', markersize=10, markerfacecolor='red', markeredgecolor='red')\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()\n",
    "\n",
    "plot_f1_per_value(usa_overview, \"Level 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "usa_predicted_labels_zero_shot.to_csv('out_usa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Testing for Africa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "africa_predicted_labels_zero_shot, africa_true_labels_zero_shot = Prompting.zero_shot_sequence(africa_test_arguments, values, llm, africa_labels_level1, africa_labels_level2, africa_labels_level3, africa_labels_level4a, africa_labels_level4b, True, False)\n",
    "\n",
    "africa_predicted_labels_zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "africa_true_labels_zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "africa_overview = evaluate(africa_predicted_labels_zero_shot, africa_true_labels_zero_shot, Processing.get_value_name_list(values), 1.0)\n",
    "africa_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "africa_predicted_labels_zero_shot.to_csv('out_africa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Testing for China"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "china_predicted_labels_zero_shot, china_true_labels_zero_shot = Prompting.zero_shot_sequence(china_test_arguments, values, llm, china_labels_level1, china_labels_level2, china_labels_level3, china_labels_level4a, china_labels_level4b, True, False)\n",
    "\n",
    "china_predicted_labels_zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "china_overview = evaluate(china_predicted_labels_zero_shot, china_true_labels_zero_shot, Processing.get_value_name_list(values), 0.0)\n",
    "china_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "china_predicted_labels_zero_shot.to_csv('out_china.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Testing for India"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "india_predicted_labels_zero_shot, india_true_labels_zero_shot = Prompting.zero_shot_sequence(india_test_arguments, values, llm, india_labels_level1, india_labels_level2, india_labels_level3, india_labels_level4a, india_labels_level4b, True, False)\n",
    "\n",
    "india_predicted_labels_zero_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "india_overview = evaluate(india_predicted_labels_zero_shot, india_true_labels_zero_shot, Processing.get_value_name_list(values), 0.0)\n",
    "india_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "india_predicted_labels_zero_shot.to_csv('out_india.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Zero-shot CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predicted_labels_zero_shot_cot, true_labels_zero_shot_cot = Prompting.zero_shot_sequence(test_arguments, values, llm, test_labels, True, 0, True)\n",
    "\n",
    "predicted_labels_zero_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f1_zero_shot = Evaluation.f1_overview(predicted_labels_zero_shot, true_labels_zero_shot, value_name_list)\n",
    "f1_zero_shot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Plotting.plot_f1_per_value(f1_zero_shot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Writing to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "IO.write_to_file(f1_zero_shot, \"../results/Schwartz/Zero-shot/gpt-3.5-instruct.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
